{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spam.txt\")\n",
    "mails = {}\n",
    "# agregapar las dos clases al diccionario\n",
    "mails[\"ham\"] = []\n",
    "mails[\"spam\"] = []\n",
    "palabras={}\n",
    "# por cada linea, agregar a ham o spam el texto\n",
    "for mail in f: \n",
    "    mail = mail.rstrip()\n",
    "    partes = mail.split(\"\\t\")\n",
    "    mails[partes[0]].append(partes[1])\n",
    "    # separar palabra por palabra\n",
    "    for palabra in partes[1].split(\" \"): \n",
    "        if palabra not in palabras: \n",
    "            palabras[palabra]=0\n",
    "            # agregar a la cuenta de cada palabra \n",
    "        palabras[palabra]+=1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'you', 'I', 'a', 'the', 'and', 'in', 'is', 'i', 'u', 'for', 'my', 'of', 'me', 'your', 'on', 'have', '2', '', 'that', 'it', 'are', 'call', 'or', 'be', 'at', 'with', 'not', 'will', 'get', 'can', 'U', 'ur', 'so', \"I'm\", 'but', '&lt;#&gt;', 'You', 'from', '4', 'up', 'do', '.', 'if', 'just', 'go', 'when', 'like', 'know', 'this', 'we', 'all', 'out', 'got', 'was', 'come', 'now', '?', 'am', '...', 'want', 'by', 'Call', 'time', 'about', 'send', 'only', 'then', 'what', 'going', 'need', 'n', \"I'll\", 'How', 'still', 'as', 'If', 'one', 'But', 'its', 'he', 'our', 'No', 'text', 'no', 'been', 'Just', 'We', 'there', 'So', 'some', 'has', 'see', 'love', 'good', \"don't\", 'think', 'Do', 'r', 'how', 'back', 'any', '&', 'an', 'home', 'ü', 'tell', 'Your', 'day', 'take', 'What', 'her', 'My', 'dont', 'free', 'And', 'Ok', 'me.', 'A', 'The', 'mobile', 'd', 'who', 'they', \"i'm\", 'FREE', 'make', 'new', 'give', 'him', '-', 'phone', 'more', 'later', 'now.', 'she', '&amp;', 'much', 'Have', 'you.', 'ask', 'To', 'Are', 'This', 'Hey', 'had', 'great', 'txt', 'way', 'should', 'here', 'reply', 'Can', 'say', 'claim', 'Good', 'da', 'e', 'meet', 'Its', 'after', 'really', 'too', 'them', 'number', 'week', 'very', 'Txt', 'lor.', 'contact', 'would', 'said', '1', 'doing', 'Please', 'pick', 'every', 'find', 'miss', 'night', 'Pls', 'work', 'Oh', 'did', 'sent', 'stop', 'right', 'ok', 'It', 'Hi', 'last', 'Ur', ':)', 'it.', 'gonna', 'next', 'Then', 'Not', 'where', 'message', 'lor...', 'could', '!', 'keep', 'per', 'feel', 'let', 'now!', 'buy', 'cos', 'went', 'cant', 'many', 'around', \"it's\", 'He', 'were', 'sure', 'tomorrow', 'told', 'his', 'Is', 'hope', \"can't\", 'Sorry,', 'Sorry', 'Ü', '3', 'Reply', 'b', 'Did', 'us', 'cash', 'please', 'before', 'wan', 'msg', 'Lol', 'anything', 'why', 'even', 'something', 'Happy', 'which', 'today', 'other', 'day.', 'leave', 'dun', 'getting', 'always', 'When', 'also', 'Hope', 'Nokia', 'wait', 'already', 'won', 'down', 'place', 'service', 'STOP', 'someone', 'c', 'prize', 'She', 'Dear', 'care', 'thing', 'over', 'being', 'Yeah', 'waiting', \"It's\", 'Gud', 'coming', 'Text', 'trying', 'few', 'off', \"I've\", 'first', 'Thanks', 'Get', \"you're\", 'things', 'Where', 'R', 'For', 'dear', 'money', 'people', 'having', 'Free', 'win', 'As', 'try', 'well', \"didn't\", 'late', 'Will', 'Dont', 'thk', 'In', 'use', 'thought', 'awarded', 'Or', 'life', 'draw', 'pls', 'than', 'That', 'im', 'sleep', '*', 'Yes', 'happy', 'Send', 'da.', '1st', 'talk', 'bit', 'shows', 'wat', 'Well', 'receive', 'customer', 'finish', 'morning', 'car', 'x', 'you,', 'best', '£1000', 'because', 'friend', 'dat', 'into', 'All', 'They', 'stuff', 'lunch', 'YOU', 'never', 'there.', 'hi', 'another', 'guys', 'ready', 'meeting', 'Now', 'URGENT!', 'wont', \"that's\", ',', 'sorry', 'same', 'Yup', 'between', 'PO', 'long', 'called', 'might', '5', 'Claim', 'Mobile', 'eat', '2nd', 'half', 'special', 'C', 'home.', 'UR', 'name', 'better', 'big', 'ill', 'wish', 'you!', \"i'll\", 'friends', 'help', '+', 'New', 'again', 'quite', 'IS', 'soon', 'v', 'pay', 'K', 'may', 'tonight', 'looking', 'real', '150ppm', 'CALL', 'little', 'end', 'See', 'nice', 'reach', 'watch', 'didnt', 'you?', 'made', 'Wat', 'selected', 'latest', 'today.', 'Love', 'live', 'look', 'wanted', 'Tell', 'class', '16', 'lot', 'ME', 'Why', 'u.', 'without', 'ok.', 'hour', 'chance', 'days', 'Only', 'until', 'wif', 'goes', 'hear', 'came', 'babe', 'says', 'job', 'able', 'time.', 'person', 'two', 'mins', 'shit', 'THE', 'entry', 'part', 'now?', 'NOW', 'guaranteed', 'chat', 'Am', 'ever', 'minutes', 'put', 'wanna', 'dis', \"That's\", 'early', 'left', 'dinner', 'room', 'done', 'most', \"he's\", 'it,', 'year', 'later.', 'abt', '4*', 'do.', 'Got', 'face', 'asked', \"Don't\", 'MY', \"i've\", 'mind', 'start', 'probably', 'network', 'remember', 'that.', 'play', 'check', 'AT', 'means', 'Box', 'forgot', 'Ok...', '&lt;DECIMAL&gt;', '500', 'plan', 'smile', 'attempt', 'lor', 'bring', 'till', 'word', 'fun', 'enough', '16+']\n"
     ]
    }
   ],
   "source": [
    "cantidadAUsar = 500\n",
    "palabrasOrdenadas = sorted(palabras.items(), key = lambda item:item[1], reverse = True)\n",
    "top = list(map(lambda x:x[0], palabrasOrdenadas))[:cantidadAUsar]\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []\n",
    "etiquetas = []\n",
    "# por cada correo\n",
    "for correo in mails[\"ham\"]: \n",
    "#     agrega la etiqueta correcta \n",
    "    etiquetas.append(0)\n",
    "#     llevar la cuenta de cada palabra en el top \n",
    "    cuenta=[]\n",
    "    separado = correo.split(\" \")\n",
    "#     por cada palabra en el top \n",
    "    for palabraTop in top: \n",
    "#         contamos y agregamos \n",
    "        cuenta.append(separado.count(palabraTop))\n",
    "    datos.append(cuenta)\n",
    "\n",
    "# por cada correo \n",
    "for correo in mails[\"spam\"]: \n",
    "#     agrega la etiqueta correcta \n",
    "    etiquetas.append(0)\n",
    "#     llevar la cuenta de cada palabra en el top \n",
    "    cuenta=[]\n",
    "    separado = correo.split(\" \")\n",
    "#     por cada palabra en el top \n",
    "    for palabraTop in top: \n",
    "#         contamos y agregamos \n",
    "        cuenta.append(separado.count(palabraTop))\n",
    "    datos.append(cuenta)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(datos, etiquetas, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etnaramirez/Documents/8 semestre/IC/IC/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "classifier = MultinomialNB().fit(Xtrain, ytrain)\n",
    "prediccion = classifier.predict(Xtest)\n",
    "\n",
    "print(accuracy_score(ytest, prediccion), f1_score(ytest, prediccion))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear contenedores para los datos y etiquetas\n",
    "datos = []\n",
    "etiquetas = []\n",
    "# agregar los correos de ham y poner las etiquetas correctas\n",
    "for correo in mails[\"ham\"]: \n",
    "    datos.append(correo)\n",
    "    etiquetas.append(0)\n",
    "# agregar los correos de spam y poner las etiquetas correctas\n",
    "for correo in mails[\"spam\"]: \n",
    "    datos.append(correo)\n",
    "    etiquetas.append(1)\n",
    "# importar la liberaria para vectorizar \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(datos, etiquetas, train_size = 0.8)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "Xtrain = vectorizer.fit_transform(Xtrain)\n",
    "\n",
    "Xtest = vectorizer.transform(Xtest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cacbb3c092fab53a60e9a71562ab76ab5ec75d7d3bd960d0f30450a9f52945e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('IC': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
